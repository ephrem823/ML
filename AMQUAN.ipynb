{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAtc3g3QKQ5maaeDfTkU5N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "with open(\"/content/haramaya_amharic_qa.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "qas = []\n",
        "for art in data:\n",
        "    for p in art[\"paragraphs\"]:\n",
        "        for q in p[\"qas\"]:\n",
        "            qas.append({\n",
        "                \"context\": p[\"context\"],\n",
        "                \"question\": q[\"question\"],\n",
        "                \"answer\": q[\"answers\"][0][\"text\"]\n",
        "            })\n",
        "\n",
        "def clean(t):\n",
        "    t = re.sub(r\"[A-Za-z0-9!\\\"#$%&'()*+,-./:;<=>?@\\[\\]\\\\^_`{|}~]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "stop = set([\"·ä•·äì\",\"·ãà·ã≠·àù\",\"·äê·ãç\",\"·äì·âµ\",\"·â†\",\"·ã®\",\"·àà\",\"·ä•·äï·ã∞\",\"·ä•·ãö·àÖ\",\"·ã≠\",\"·ãç·àµ·å•\"])\n",
        "def tokenizer(t): return [w for w in clean(t).split() if w not in stop]\n",
        "\n",
        "questions = [q[\"question\"] for q in qas]\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None)\n",
        "X = vectorizer.fit_transform(questions)\n",
        "\n",
        "ask = input(\"üó£Ô∏è ·ã®·ä•·à≠·àµ·ãé ·å•·ã´·âÑ ·ã´·àµ·åà·â°·ç¶ \")\n",
        "ask_vec = vectorizer.transform([ask])\n",
        "scores = cosine_similarity(ask_vec, X)[0]\n",
        "best = scores.argmax()\n",
        "\n",
        "print(\"\\nü§î ·â∞·àò·à≥·à≥·ã≠ ·å•·ã´·âÑ:\", qas[best][\"question\"])\n",
        "print(\"‚úÖ ·àò·àç·àµ:\", qas[best][\"answer\"])"
      ],
      "metadata": {
        "id": "9ehenVk18M_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}